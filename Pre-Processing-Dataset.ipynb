{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5Z97wr29mjb"
      },
      "source": [
        "# **Test 080424**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IVax7Vjq9xBr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Jq09-vnR9q8E"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_and_sample_data(file_path, sample_size):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    \n",
        "    sampled_lines = random.sample(lines, min(sample_size, len(lines)))\n",
        "    \n",
        "    sampled_data = []\n",
        "    for line in sampled_lines:\n",
        "        try:\n",
        "            str_text = line.replace(\"true\", \"True\").replace(\"false\", \"False\")\n",
        "            raw_sample = eval(str_text)\n",
        "            sampled_data.append(raw_sample)\n",
        "        except:\n",
        "            pass  # Ignore lines that raise errors\n",
        "    \n",
        "    return sampled_data\n",
        "\n",
        "def read_txt_file_to_list(file_path):\n",
        "    records = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            records.append(line.strip())\n",
        "    return records\n",
        "\n",
        "\n",
        "def remove_duplicate_rows(df):\n",
        "    df = df.drop_duplicates(subset=['reviewText', 'asin', 'reviewerID'])\n",
        "    return df\n",
        "\n",
        "def remove_duplicate_rows_ver2(df):\n",
        "    df = df.drop_duplicates(subset=['reviewText', 'itemID', 'reviewerID'])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_number = 0\n",
        "dataset_name = \"Toys_and_Games_5\"  \n",
        "json_file_path = \"./data/\" + dataset_name + \".json\"  \n",
        "output_directory = \"data/\"  \n",
        "small_dataset = \"Small_\"+ dataset_name  + \".json\"\n",
        "chunk_size = 10000  \n",
        "\n",
        "extracted_data = output_directory + \"extract/\" + dataset_name + \"_extracted_data_\" + str(file_number) + \".csv\"\n",
        "filtered_data = output_directory + \"filtered/\" + dataset_name + \"_filtered_data_\" + str(file_number) + \".csv\"\n",
        "outliner_data = output_directory + \"outliner/\" + dataset_name + \"_outliner_data_\" + str(file_number) + \".csv\"\n",
        "\n",
        "final_json_name = dataset_name + \"_Filtered\" + \".json\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_size = chunk_size  \n",
        "sampled_data = read_and_sample_data(json_file_path, sample_size)\n",
        "data_df = pd.DataFrame(sampled_data)\n",
        "print(data_df)\n",
        "\n",
        "output_file_path = os.path.join(output_directory, f\"Small_{dataset_name}.json\")\n",
        "data_df.to_json(output_file_path, orient='records', lines=True)\n",
        "\n",
        "print(f\"Saved {len(data_df)} records to {output_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5SZuWLY9zhy"
      },
      "outputs": [],
      "source": [
        "data = pd.read_json(output_directory + small_dataset, lines=True)\n",
        "print(data)\n",
        "data_df = pd.DataFrame(data, columns=['reviewerID', 'asin', 'overall', 'reviewText'])\n",
        "print(data_df.head())\n",
        "data_df.columns = ['reviewerID', 'asin', 'overall', 'reviewText']\n",
        "\n",
        "data_rating = data_df[\"overall\"].tolist()\n",
        "data_review = data_df[\"reviewText\"].tolist()\n",
        "data_reviewerID = data_df[\"reviewerID\"].tolist()\n",
        "data_itemID = data_df[\"asin\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Get the number of unique users and items\n",
        "num_users = len(data_df['reviewerID'].unique())\n",
        "num_items = len(data_df['asin'].unique())\n",
        "\n",
        "# Display the counts\n",
        "print(f\"Number of users: {num_users}\")\n",
        "print(f\"Number of items: {num_items}\")\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "train_size = 0.7\n",
        "valid_size = 0.1\n",
        "test_size = 0.2\n",
        "\n",
        "# First, split into train and temp (valid + test)\n",
        "train_data, temp_data = train_test_split(data_df, test_size=(valid_size + test_size), random_state=42)\n",
        "\n",
        "# Then split temp_data into validation and test\n",
        "valid_data, test_data = train_test_split(temp_data, test_size=test_size / (valid_size + test_size), random_state=42)\n",
        "\n",
        "# Get sizes of the datasets\n",
        "size_train = len(train_data)\n",
        "size_valid = len(valid_data)\n",
        "size_test = len(test_data)\n",
        "\n",
        "# Display the sizes\n",
        "print(f\"Size of train set: {size_train}\")\n",
        "print(f\"Size of validation set: {size_valid}\")\n",
        "print(f\"Size of test set: {size_test}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uzR4bKv96IP",
        "outputId": "49d8bb84-1308-42d5-f7f4-d4b3332d2b2e"
      },
      "outputs": [],
      "source": [
        "print(len(data_rating))\n",
        "print(len(data_reviewerID))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh3aa--7-Omb",
        "outputId": "6ad14e4f-aef7-4a8d-9c2f-242751e6a819"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def defineRating(data_rating):\n",
        "  T_v = []\n",
        "  for rating in data_rating:\n",
        "    if rating >= 4:\n",
        "      T_v.append(1)\n",
        "    else:\n",
        "      T_v.append(-1)\n",
        "  return T_v\n",
        "\n",
        "T_v = defineRating(data_rating)\n",
        "data = {'id': range(len(T_v)), 'T_v': T_v}\n",
        "df_rating = pd.DataFrame(data)\n",
        "\n",
        "# Print the dataframe\n",
        "print(df_rating)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_rating['reviewerID'] = data_reviewerID\n",
        "df_rating['asin'] = data_itemID\n",
        "df_rating['overall'] = data_rating\n",
        "df_rating['reviewText'] = data_review\n",
        "print(df_rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SODCM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "import contractions\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from flair.data import Sentence\n",
        "from flair.models import TextClassifier\n",
        "from transformers import pipeline\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "tagger = TextClassifier.load('en-sentiment')\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "pos_words = read_txt_file_to_list(output_directory + \"positive-words.txt\")\n",
        "neg_words = read_txt_file_to_list(output_directory + \"negative-words.txt\")\n",
        "print(pos_words)\n",
        "print(neg_words)\n",
        "\n",
        "word_type = ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS']\n",
        "brands = ['dove', 'aveda', 'silver']\n",
        "keywords = ['overall', 'summary']\n",
        "\n",
        "def handle_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "def get_sentiment_words(text):\n",
        "    text = handle_contractions(text)\n",
        "    words = word_tokenize(text)\n",
        "    sentiment_words = [word for word in words if word.lower() not in stop_words and sia.polarity_scores(word)['compound'] != 0]\n",
        "    return sentiment_words\n",
        "\n",
        "def sentiment_analysis_flair(sentence):\n",
        "    if not sentence.strip():\n",
        "        return 0.0\n",
        "    \n",
        "    flair_sentence = Sentence(sentence)\n",
        "    tagger.predict(flair_sentence)\n",
        "    \n",
        "    sentiment_value = flair_sentence.labels[0].value\n",
        "    sentiment_score = flair_sentence.labels[0].score\n",
        "    bias = 1.75 if any(keyword.lower() in sentence.lower() for keyword in keywords) else 1.0\n",
        "    \n",
        "    return sentiment_score * bias if sentiment_value == 'POSITIVE' else -sentiment_score * bias\n",
        "\n",
        "def check_string(input_value):\n",
        "    return input_value if isinstance(input_value, str) else ''\n",
        "\n",
        "def separate_sentences(text):\n",
        "    text = check_string(text)\n",
        "    text = handle_contractions(text)  # Expand contractions before splitting\n",
        "    doc = nlp(text)\n",
        "    sentences = []\n",
        "    current_sentence = \"\"\n",
        "\n",
        "    conjunctions = [\"but\", \"and\", \"or\", \"although\", \"however\", \"because\", \"therefore\", \"meanwhile\", \n",
        "                    \"moreover\", \"nevertheless\", \"nonetheless\", \"otherwise\", \"thus\", \"yet\",\n",
        "                    \"which\", \"who\", \"whose\", \"whom\", \"where\", \"when\", \"why\", \"that\"]\n",
        "    \n",
        "    for token in doc:\n",
        "        if token.is_sent_start or token.text == \"\\n\":\n",
        "            if current_sentence:\n",
        "                sentences.append(current_sentence.strip())\n",
        "            current_sentence = token.text\n",
        "        elif token.text.lower() in conjunctions:\n",
        "            if any(brand.lower() in current_sentence.lower() for brand in brands):\n",
        "                current_sentence += \" \" + token.text\n",
        "            elif current_sentence:\n",
        "                sentences.append(current_sentence.strip())\n",
        "                current_sentence = token.text\n",
        "        else:\n",
        "            current_sentence += \" \" + token.text\n",
        "\n",
        "    # Check for the last sentence\n",
        "    if current_sentence:\n",
        "        sentences.append(current_sentence.strip())\n",
        "    \n",
        "    # Post-process to ensure sentences are meaningful\n",
        "    processed_sentences = []\n",
        "    for i in range(len(sentences)):\n",
        "        sentence = sentences[i]\n",
        "        if sentence.endswith(tuple(conjunctions)) and i < len(sentences) - 1:\n",
        "            # Merge with the next sentence if the sentence ends with a conjunction\n",
        "            sentence += \" \" + sentences[i + 1]\n",
        "            processed_sentences.append(sentence.strip())\n",
        "        elif sentence:\n",
        "            processed_sentences.append(sentence.strip())\n",
        "    \n",
        "    return processed_sentences\n",
        "\n",
        "# Sentiment analyzer dùng transformer\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def split_sentences_and_filter_sentiment(text):\n",
        "    sentences = separate_sentences(text)\n",
        "    if len(sentences) == 1 and not re.search(r'[.!?]', text):\n",
        "        sentences = [text]\n",
        "\n",
        "    filtered_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if not sentence:\n",
        "            continue\n",
        "\n",
        "        words = word_tokenize(sentence)\n",
        "        contains_sentiment = (any(sia.polarity_scores(word)['compound'] != 0 for word in words) or\n",
        "                              any(word.lower() in pos_words or word.lower() in neg_words for word in words))\n",
        "\n",
        "        sentence_flair = Sentence(sentence)\n",
        "        tagger.predict(sentence_flair)\n",
        "        is_a = any(\n",
        "            label.value in word_type for token in sentence_flair.tokens for label in token.get_labels('pos')\n",
        "        )\n",
        "\n",
        "        if any(word.lower() in brands for word in words):\n",
        "            contains_sentiment = False\n",
        "            is_a = False\n",
        "\n",
        "        if contains_sentiment or is_a:\n",
        "            filtered_sentences.append(sentence)\n",
        "        # else:\n",
        "        #     print(\"remove: \", sentence)\n",
        "\n",
        "    if not filtered_sentences:\n",
        "        filtered_sentences = sentences\n",
        "\n",
        "    return filtered_sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "predictRating = []\n",
        "text = \"Lavender water. This has a nice scent and the sprayer sprays well, but it is so weak that the scent disappears within a few minutes If I spray more, the sheets get damp. I received a free bottle in exchange for an honest review and I was pretty excited about having lavender-scented sheets, but I won't be buying any of this item and can't recommend it. I have tried this company's soaps, though, and they are wonderfult\"\n",
        "\n",
        "sentences = split_sentences_and_filter_sentiment(text)\n",
        "print(sentences)\n",
        "total_sentiment = 0\n",
        "for sentence in sentences:\n",
        "    # sentence = remove_stopwords(sentence)\n",
        "    score = sentiment_analysis_flair(sentence)\n",
        "    print(sentence, score)\n",
        "    total_sentiment += score\n",
        "    # print(total_sentiment)\n",
        "print(total_sentiment)\n",
        "if total_sentiment/len(sentences) < -0.2:\n",
        "    predictRating.append(-1)\n",
        "    print(\"Result: -1\")\n",
        "else:\n",
        "    predictRating.append(1)\n",
        "    print(\"Result: 1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import os\n",
        "\n",
        "predictRating = []\n",
        "def process_and_save(df_rating, output_file):\n",
        "    output_df = pd.DataFrame(columns=['reviewerID', 'asin', 'predictRating', 'T_v', 'overall', 'reviewText', 'filteredReviewText'])\n",
        "    score = 0\n",
        "    for i, row in tqdm.tqdm(df_rating.iterrows(), desc=\"Processing\", total=len(df_rating)):\n",
        "        sentences = split_sentences_and_filter_sentiment(row['reviewText'])\n",
        "        if not sentences:\n",
        "            print(f\"Warning: No sentences after filtering for review ID {row['reviewerID']} and asin {row['asin']}\")\n",
        "\n",
        "        total_sentiment = sum(sentiment_analysis_flair(sentence) for sentence in sentences)\n",
        "        if total_sentiment >= -0.2:\n",
        "            score = 1\n",
        "        else:\n",
        "            score = -1\n",
        "        predictRating.append(score)\n",
        "        output_df.loc[len(output_df)] = { 'reviewerID': row['reviewerID'],\n",
        "                                          'asin': row['asin'],\n",
        "                                          'predictRating': score,\n",
        "                                          'T_v': row['T_v'],\n",
        "                                          'overall': row['overall'],\n",
        "                                          'reviewText': row['reviewText'],\n",
        "                                          'filteredReviewText': \" \".join(sentences) }\n",
        "        \n",
        "        if (i + 1) % 1000 == 0:\n",
        "            output_df.to_csv(output_file, mode='a', header=not os.path.exists(output_file), index=False)\n",
        "            output_df = pd.DataFrame(columns=['reviewerID', 'asin', 'predictRating', 'T_v', 'overall', 'reviewText', 'filteredReviewText'])\n",
        "    \n",
        "    if not output_df.empty:\n",
        "        output_df.to_csv(output_file, mode='a', header=not os.path.exists(output_file), index=False)\n",
        "\n",
        "process_and_save(df_rating, extracted_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pd.read_csv(extracted_data)\n",
        "output_df = pd.DataFrame(output)\n",
        "print(\"Length Original Dataset: \", len(output_df))\n",
        "\n",
        "outliner_rows = []\n",
        "filtered_rows = []\n",
        "\n",
        "for i, row in output_df.iterrows():\n",
        "    row['overall_new'] = row['overall']\n",
        "    \n",
        "    if row['predictRating'] != row['T_v']:\n",
        "        current_asin = row['asin']\n",
        "        median_value = output_df[output_df['asin'] == current_asin]['overall'].quantile(0.5) \n",
        "        \n",
        "        row['overall_new'] = float(round((row['overall'] + median_value) / 2))\n",
        "        # print(row['overall_new'])\n",
        "        print(row)\n",
        "        outliner_rows.append(row)\n",
        "    filtered_rows.append(row)\n",
        "\n",
        "outliner = pd.DataFrame(outliner_rows)\n",
        "filteredRecords = pd.DataFrame(filtered_rows)\n",
        "\n",
        "outliner.to_csv(outliner_data, index=False, float_format='%.6f')\n",
        "filteredRecords.to_csv(filtered_data, index=False, float_format='%.6f')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuation = set(string.punctuation)\n",
        "\n",
        "def remove_stopwords_and_punctuation(text):\n",
        "    # Kiểm tra nếu text là None hoặc NaN\n",
        "    if pd.isnull(text):\n",
        "        return \"\" \n",
        "    text = text.replace(\"\\n\", \" \").replace(\"\\\\/\", \" \").replace(\"\\\\\\\"\", \" \").replace(\"`\",\"\").replace(\"\\\"\",\"\")\n",
        "    return text\n",
        "\n",
        "# Load json data to dataframe\n",
        "raw_data = pd.read_json(output_directory + small_dataset, lines=True)\n",
        "print(\"Dataset: \", len(raw_data))\n",
        "\n",
        "tqdm.pandas() \n",
        "raw_data['filteredReviewText'] = raw_data['reviewText'].progress_apply(remove_stopwords_and_punctuation)\n",
        "raw_data['combined_key'] = raw_data['reviewerID'].astype(str) + raw_data['asin'].astype(str) + raw_data['reviewText'].astype(str)\n",
        "filteredRecords['combined_key'] = filteredRecords['reviewerID'].astype(str) + filteredRecords['asin'].astype(str) + filteredRecords['reviewText'].astype(str)\n",
        "\n",
        "raw_data['filteredReviewText'] = None\n",
        "raw_data['overall_new'] = raw_data['overall']\n",
        "\n",
        "for index, row in tqdm(raw_data.iterrows(), total=len(raw_data)):\n",
        "    combined_key = row['combined_key']\n",
        "    \n",
        "    matching_row = filteredRecords[filteredRecords['combined_key'] == combined_key]   \n",
        "    if not matching_row.empty:\n",
        "        raw_data.at[index, 'filteredReviewText'] = matching_row['filteredReviewText'].values[0]\n",
        "        raw_data.at[index, 'overall_new'] = matching_row['overall_new'].values[0]\n",
        "\n",
        "raw_data = raw_data.drop(columns=['combined_key'])\n",
        "filteredRecords = filteredRecords.drop(columns=['combined_key'])\n",
        "\n",
        "raw_data.to_json(output_directory + small_dataset, orient='records', lines=True)\n",
        "data_filtered = pd.read_json(output_directory + small_dataset, lines=True)\n",
        "\n",
        "print(\"Final dataset length: \", len(data_filtered))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "def backup_and_delete_files(folder_path, backup_path, backup_folder_name, date, extensions=[\".csv\"]):\n",
        "    backup_folder_path = os.path.join(backup_path, backup_folder_name + \"_\" + date)\n",
        "    print(f\"Thư mục sao lưu: {backup_folder_path}\")\n",
        "    \n",
        "    if not os.path.exists(backup_folder_path):\n",
        "        print(f\"Tạo thư mục sao lưu mới: {backup_folder_path}\")\n",
        "        os.makedirs(backup_folder_path)\n",
        "    \n",
        "    for ext in extensions:\n",
        "        files = glob.glob(os.path.join(folder_path, f\"*{ext}\"))\n",
        "        for file_path in files:\n",
        "            try:\n",
        "                shutil.copy(file_path, backup_folder_path)\n",
        "                print(f\"Đã sao chép: {file_path} tới {backup_folder_path}\")\n",
        "                os.remove(file_path)\n",
        "                print(f\"Đã xóa: {file_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Không thể sao chép hoặc xóa {file_path}. Lỗi: {e}\")\n",
        "\n",
        "# Ví dụ sử dụng:\n",
        "backup_and_delete_files(\"feature\", \"backup\", \"BKfeature\", \"170824\", extensions=[\".csv\"])\n",
        "backup_and_delete_files(\"feature_originalmethod\", \"backup\", \"BKfeature_originalmethod\", \"170824\", extensions=[\".csv\"])\n",
        "backup_and_delete_files(\"data\", \"backup\", \"BKdata\", \"170824\", extensions=[\".csv\"])\n",
        "backup_and_delete_files(\"chkpt\", \"backup\", \"BK_chkpt\", \"170824\", extensions=[\".pt\", \".pkl\", \"npz\"])\n",
        "backup_and_delete_files(\"output\", \"backup\", \"BK_output\", \"170824\", extensions=[\".model\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
